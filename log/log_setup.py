"""
MIT License

Copyright (c) 2021 Garett MacGowan

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""

import sys

from typing import Optional

from logging import Logger
import logging
import logging.handlers

from multiprocessing import Manager, Queue, current_process

from threading import Thread


def get_logger(name: str, queue: Optional[Queue] = None) -> Logger:
    """
        This function gets a logger instance.

        Usage:
        1) Call logger_init() and keep the LoggerManager for the life of the program.
        2) Import get_logger(__name__) wherever you want to use the logger.
        3) Use the logger, logger.info('your message')

        4) When using multiprocessing...

            import log.globals
            Pass log.globals.logger_queue as a parameter to the multiprocessing function explicitly
            (needed due to process spawning on Windows OS).

            e.g.
            pool = mp.Pool(processes=mp.cpu_count())
            pool.imap_unordered(func=partial(
                my_function,
                queue=log.globals.logger_queue,
                parameters=parameters
            ))

            Set up a logger instance from within the function that multiprocessing is being applied to. It will communicate
            with the root logger using the queue.

            e.g.
            def my_function(queue, parameters):
                multiprocessing_logger = get_logger(__name__, queue=queue)
                multiprocessing_logger.info('testing logger in multiprocessing')

        5) When you are finished logging, close the logger using the LoggerManager returned from logger_init() (step 1)

            e.g.
            logger_manager.terminate_logger()

        Args:
            name: The name for the logger.
            queue: A Queue instance generated by logger_init(), held in the variable log.globals.logger_queue

        Returns:

    """
    if current_process().name != 'MainProcess' and not Queue:
        """
        Don't create the logger, state reached may be due to Windows process spawning (imports may be re-evaluated
        upon spawn of a new process.
        """
        pass
    elif queue is not None:
        # Set up the queue handler for the logger instance.
        queue_handler = logging.handlers.QueueHandler(queue)
        queue_handler.set_name(name=current_process().pid.__str__())
        # Get root logger instance.
        root = logging.getLogger()
        root.setLevel(logging.INFO)
        # Add the handler if it doesn't already exist.
        if queue_handler.name not in [x.name for x in root.handlers]:
            root.addHandler(queue_handler)

        logger = logging.getLogger(name=name)

        return logger


class RedirectToLogger(object):
    """
    Used to redirect stdout and stderr to logger in hook/__init__.
    """
    def __init__(self, logger, log_level=logging.INFO):
        self.logger = logger
        self.log_level = log_level

    def write(self, message):
        for line in message.rstrip().splitlines():
            self.logger.log(self.log_level, line.rstrip())

    def flush(self):
        pass


class LoggerManager:

    def __init__(self, logger_thread: Thread):
        self.logger_thread = logger_thread

    def terminate_logger(self):
        """
        This method terminates the logger thread. It should be called when the program is complete (or when you are done
        logging).
        Returns:

        """
        log.globals.logger_queue.put(None)
        self.logger_thread.join()


def _configure_logging_handlers() -> None:
    """
    This function configures the logging handlers for the root logger.
    Returns:

    """
    root = logging.getLogger()
    root.setLevel(logging.INFO)

    # Define the log formatter.
    log_formatter = logging.Formatter("%(asctime)s: %(levelname)7s > %(message)s")

    # Define the log file handler.
    file_handler = logging.handlers.RotatingFileHandler('log/logs/scheduled_vm.log', maxBytes=10000000, backupCount=6)
    file_handler.setFormatter(log_formatter)
    root.addHandler(file_handler)

    # Define the stream handler
    stderr_handler = logging.StreamHandler(sys.stderr)
    stderr_handler.setFormatter(log_formatter)
    root.addHandler(stderr_handler)

    # Redirect stdout to a logger instance.
    stdout_logger = get_logger('stdout')
    stdout_logger = RedirectToLogger(logger=stdout_logger, log_level=logging.INFO)
    sys.stdout = stdout_logger

    # Redirect stderr to a logger instance.
    stderr_logger = get_logger('stderr')
    stderr_logger = RedirectToLogger(logger=stderr_logger, log_level=logging.WARNING)
    sys.stderr = stderr_logger


def _lt(queue: Queue) -> None:
    """
    This function acts as the thread that listens to the logger queue and sends queued logs to the logger instance.
    Args:
        queue: A multiprocessing Queue, managed my a multiprocessing Manager.

    Returns:

    """
    while True:
        record = queue.get()
        if record is None:
            break
        logger = logging.getLogger(record.name)
        logger.handle(record)


def logger_init() -> LoggerManager:
    """
    This function initializes a logger as well as a thread to process logs produced by concurrent processes. Logs from
    concurrent processes should be passed through the multiprocessing queue stored in log.globals.logger_queue.

    Returns: A LoggerManager instance which can be used to terminate the logger thread at cleanup time.
    """
    _configure_logging_handlers()

    log.globals.logger_queue = Manager().Queue()

    logger_thread = Thread(target=_lt, args=(log.globals.logger_queue,))
    logger_thread.start()

    return LoggerManager(logger_thread=logger_thread)
